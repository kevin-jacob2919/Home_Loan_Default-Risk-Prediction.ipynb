{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIxcqV4aALkO",
        "outputId": "6e094fb2-fd63-46d0-dfa9-1364c5ea63f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   BAD  LOAN  MORTDUE     VALUE   REASON     JOB   YOJ  DEROG  DELINQ  \\\n",
            "0    1  1100  25860.0   39025.0  HomeImp   Other  10.5    0.0     0.0   \n",
            "1    1  1300  70053.0   68400.0  HomeImp   Other   7.0    0.0     2.0   \n",
            "2    1  1500  13500.0   16700.0  HomeImp   Other   4.0    0.0     0.0   \n",
            "3    1  1500      NaN       NaN      NaN     NaN   NaN    NaN     NaN   \n",
            "4    0  1700  97800.0  112000.0  HomeImp  Office   3.0    0.0     0.0   \n",
            "\n",
            "        CLAGE  NINQ  CLNO  DEBTINC  \n",
            "0   94.366667   1.0   9.0      NaN  \n",
            "1  121.833333   0.0  14.0      NaN  \n",
            "2  149.466667   1.0  10.0      NaN  \n",
            "3         NaN   NaN   NaN      NaN  \n",
            "4   93.333333   0.0  14.0      NaN  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5960 entries, 0 to 5959\n",
            "Data columns (total 13 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   BAD      5960 non-null   int64  \n",
            " 1   LOAN     5960 non-null   int64  \n",
            " 2   MORTDUE  5442 non-null   float64\n",
            " 3   VALUE    5848 non-null   float64\n",
            " 4   REASON   5708 non-null   object \n",
            " 5   JOB      5681 non-null   object \n",
            " 6   YOJ      5445 non-null   float64\n",
            " 7   DEROG    5252 non-null   float64\n",
            " 8   DELINQ   5380 non-null   float64\n",
            " 9   CLAGE    5652 non-null   float64\n",
            " 10  NINQ     5450 non-null   float64\n",
            " 11  CLNO     5738 non-null   float64\n",
            " 12  DEBTINC  4693 non-null   float64\n",
            "dtypes: float64(9), int64(2), object(2)\n",
            "memory usage: 605.4+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load dataset (replace with your file path)\n",
        "df = pd.read_csv('home_loan_default_risk.csv')\n",
        "\n",
        "# Basic info\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Original code tried to impute 'AMT_INCOME_TOTAL' and 'AMT_CREDIT'.\n",
        "# These columns are not present in the loaded DataFrame.\n",
        "# Based on the df.head() and df.info(), we will use 'LOAN' as the credit amount.\n",
        "# Other numerical columns that may have missing values are also imputed.\n",
        "df[['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC']] = imputer.fit_transform(df[['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC']])\n",
        "\n",
        "# Encode categorical variables\n",
        "le = LabelEncoder()\n",
        "# Original code tried to encode 'NAME_CONTRACT_TYPE', which is not present.\n",
        "# We will use 'REASON' and 'JOB' as categorical features, filling NaNs with 'Unknown' first.\n",
        "df['REASON'] = df['REASON'].fillna('Unknown')\n",
        "df['JOB'] = df['JOB'].fillna('Unknown')\n",
        "df['REASON_ENCODED'] = le.fit_transform(df['REASON'])\n",
        "df['JOB_ENCODED'] = le.fit_transform(df['JOB'])\n",
        "\n",
        "# Feature engineering: Create debt-to-income ratio\n",
        "# Original code tried to create 'DEBT_TO_INCOME' using 'AMT_CREDIT' and 'AMT_INCOME_TOTAL', which are missing.\n",
        "# The 'DEBTINC' column already exists and serves this purpose, so we will use it directly.\n",
        "\n",
        "# Select features and target\n",
        "# Original code used 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'DEBT_TO_INCOME', 'NAME_CONTRACT_TYPE'.\n",
        "# Based on the available data, we will use 'LOAN', 'DEBTINC', 'REASON_ENCODED', 'JOB_ENCODED'\n",
        "# and other relevant numerical columns. 'BAD' appears to be the target variable.\n",
        "features = ['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC', 'REASON_ENCODED', 'JOB_ENCODED']\n",
        "X = df[features]\n",
        "y = df['BAD'] # 'BAD' is likely the target variable indicating default\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]"
      ],
      "metadata": {
        "id": "wbrZsR_TBfFb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example new data (as a DataFrame)\n",
        "# The features here must match the 'features' list used in the training step (cell pIxcqV4aALkO)\n",
        "new_applicant_data = pd.DataFrame({\n",
        "    'LOAN': [15000.0],\n",
        "    'MORTDUE': [50000.0],\n",
        "    'VALUE': [70000.0],\n",
        "    'YOJ': [5.0],\n",
        "    'DEROG': [0.0],\n",
        "    'DELINQ': [0.0],\n",
        "    'CLAGE': [100.0],\n",
        "    'NINQ': [1.0],\n",
        "    'CLNO': [10.0],\n",
        "    'DEBTINC': [30.0],\n",
        "    'REASON_ENCODED': [0], # Example encoded value, assuming 'DebtCon' or similar was encoded to 0\n",
        "    'JOB_ENCODED': [0]    # Example encoded value, assuming 'Office' or similar was encoded to 0\n",
        "})\n",
        "\n",
        "# Ensure the order of columns matches the 'features' list used during training\n",
        "new_applicant_data = new_applicant_data[features]\n",
        "\n",
        "# Preprocess (only transform, as scaler was fit on training data)\n",
        "# If new_applicant_data had missing values in numerical columns, you would also apply 'imputer.transform()'\n",
        "new_data_scaled = scaler.transform(new_applicant_data)\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(new_data_scaled)\n",
        "probability = model.predict_proba(new_data_scaled)[:, 1]\n",
        "print(f\"Default Prediction: {prediction[0]} (1=Default), Probability: {probability[0]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSSiYulLCTch",
        "outputId": "98034062-e7b2-48df-efcd-d7d3727b734b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Prediction: 0 (1=Default), Probability: 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CLlknMnOCW3H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}